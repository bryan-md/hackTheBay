{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bryan Dickinson\n",
      "netCDF4 1.5.4\n",
      "numpy   1.18.5\n",
      "pandas  1.1.0\n",
      "scipy 1.4.1\n",
      "matplotlib 3.3.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import netCDF4\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "PROJ_ROOT = os.path.join(os.pardir)\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -a \"Bryan Dickinson\" \n",
    "%watermark -iv -p scipy,matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions to extract the NARR data was largely taken from the [github page](https://github.com/moezilla-ml/DatabricksHackathon) Moe Steller, Grace Kim, Sarah Olson and Lucy Han's submission to the Spark AI Summit 2020/Databricks Hackathon for Social Good in response to prompt #2 Reduce the Impact of Climate Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = os.path.join(PROJ_ROOT, \n",
    "                         'data',\n",
    "                        'raw-data',\n",
    "                         'acpcp.2011.nc')\n",
    "\n",
    "nc=netCDF4.Dataset(rm)\n",
    "\n",
    "nar_path = os.path.join(PROJ_ROOT, \n",
    "                         'data',\n",
    "                        'raw-data',\n",
    "                        'narr_data',\n",
    "                       '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(os.path.join(PROJ_ROOT, \n",
    "                         'data',\n",
    "                        'processed',\n",
    "                         'lc_pol_merged_data.csv'), parse_dates=['new_date'],usecols=['new_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_df=pd.read_csv(os.path.join(PROJ_ROOT, \n",
    "                         'data',\n",
    "                        'processed',\n",
    "                         'lc_pol_merged_data.csv'),usecols=['Longitude','Latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998 2020\n"
     ]
    }
   ],
   "source": [
    "start_yr=df.new_date.min().year\n",
    "end_yr=df.new_date.max().year\n",
    "daterange = df.iloc[:,0].astype(str)\n",
    "\n",
    "print(start_yr, end_yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_range = (-80.44707800,-74.83524400)\n",
    "lat_range = (36.73004000,42.80672000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fid=urllib.request.urlretrieve(\"ftp://ftp.cdc.noaa.gov/Datasets/NARR/monolevel/air.2m.\"+str(start_yr)+\".nc\",\n",
    "#                                nar_path+\"air.2m.\"+str(start_yr)+\".nc\") \n",
    "\n",
    "    \n",
    "\n",
    "nc_fid = netCDF4.Dataset(\"/tmp/\"+\"air.2m.\"+str(start_yr)+\".nc\",'r')\n",
    "narrlats = nc_fid.variables['lat'][:].data\n",
    "narrlons = nc_fid.variables['lon'][:].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n"
     ]
    }
   ],
   "source": [
    "for i in range(start_yr, end_yr+1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to extract just the Chesapeake Bay region \n",
    "\n",
    "def extractCB(vardata,latdata,londata,latrange,lonrange):\n",
    "  latlon_inds=np.where((latdata>latrange[0]) & (latdata<latrange[1])\n",
    "                       & (londata>lonrange[0]) & (londata<lonrange[1]))\n",
    "  var_subset=vardata[:,latlon_inds[0].min():latlon_inds[0].max(),latlon_inds[1].min():latlon_inds[1].max()]\n",
    "  lat_subset=latdata[latlon_inds[0].min():latlon_inds[0].max(),latlon_inds[1].min():latlon_inds[1].max()]\n",
    "  lon_subset=londata[latlon_inds[0].min():latlon_inds[0].max(),latlon_inds[1].min():latlon_inds[1].max()]\n",
    "  return lat_subset, lon_subset, var_subset\n",
    "\n",
    "# Define a function to loop through and return the subsetted area at the times of interest\n",
    "\n",
    "def narr_subset_variable(file_prefix,varname,start_year,end_year,narr_lats,narr_lons,latrange,lonrange): \n",
    "  for i in range(start_year,end_year+1):\n",
    "#     fid=urllib.request.urlretrieve(\"ftp://ftp.cdc.noaa.gov/Datasets/NARR/monolevel/\"+file_prefix+\".\"+str(i)+\".nc\",\n",
    "#                                    \"/tmp/\"+file_prefix+\".\"+str(i)+\".nc\") \n",
    "#     fid=urllib.request.urlretrieve(\"ftp://ftp.cdc.noaa.gov/Datasets/NARR/monolevel/\"+file_prefix+\".\"+str(i)+\".nc\",\n",
    "#                                    \"/tmp/\"+file_prefix+\".\"+str(i)+\".nc\") \n",
    "    fid = \"/tmp/\"+file_prefix+\".\"+str(i)+\".nc\"\n",
    "    nc_fid = netCDF4.Dataset(fid[0])\n",
    "    if i==start_year:\n",
    "      time = nc_fid.variables['time'][:].data\n",
    "      subset_time = [dt.datetime(1800,1,1) + dt.timedelta(hours=t) for t in time]\n",
    "      vartmp = nc_fid.variables[varname][:]  # shape is time, lat, lon as shown above\n",
    "      latsubset, lonsubset, varsubset=extractCB(vartmp.data,narr_lats,narr_lons,latrange,lonrange)\n",
    "      print(i,varname,'data imported','\\n')\n",
    "    else:\n",
    "      time = nc_fid.variables['time'][:].data\n",
    "      dt_tmp = [dt.datetime(1800,1,1) + dt.timedelta(hours=t) for t in time]\n",
    "      subset_time = np.append(subset_time,dt_tmp)\n",
    "      vartmp = nc_fid.variables[varname][:]  # shape is time, lat, lon as shown above\n",
    "      _, _, varsubsettmp=extractCB(vartmp.data,narr_lats,narr_lons,latrange,lonrange)\n",
    "      varsubset=np.vstack((varsubset,varsubsettmp))\n",
    "      print(i,varname,'data imported','\\n')\n",
    "  return varsubset, subset_time, latsubset, lonsubset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to extract just the Chesapeake Bay region \n",
    "\n",
    "def extractCB(vardata,latdata,londata,latrange,lonrange):\n",
    "  latlon_inds=np.where((latdata>latrange[0]) & (latdata<latrange[1])\n",
    "                       & (londata>lonrange[0]) & (londata<lonrange[1]))\n",
    "  var_subset=vardata[:,latlon_inds[0].min():latlon_inds[0].max(),latlon_inds[1].min():latlon_inds[1].max()]\n",
    "  lat_subset=latdata[latlon_inds[0].min():latlon_inds[0].max(),latlon_inds[1].min():latlon_inds[1].max()]\n",
    "  lon_subset=londata[latlon_inds[0].min():latlon_inds[0].max(),latlon_inds[1].min():latlon_inds[1].max()]\n",
    "  return lat_subset, lon_subset, var_subset\n",
    "\n",
    "# Define a function to loop through and return the subsetted area at the times of interest\n",
    "\n",
    "def narr_subset_variable(file_prefix,varname,start_year,end_year,narr_lats,narr_lons,latrange,lonrange): \n",
    "    \n",
    "    \n",
    "    \n",
    "  for i in range(start_year,end_year+1):\n",
    "#     fid=urllib.request.urlretrieve(\"ftp://ftp.cdc.noaa.gov/Datasets/NARR/monolevel/\"+file_prefix+\".\"+str(i)+\".nc\",\n",
    "#                                    \"/tmp/\"+file_prefix+\".\"+str(i)+\".nc\") \n",
    "#     fid=urllib.request.urlretrieve(\"ftp://ftp.cdc.noaa.gov/Datasets/NARR/monolevel/\"+file_prefix+\".\"+str(i)+\".nc\",\n",
    "#                                    \"/tmp/\"+file_prefix+\".\"+str(i)+\".nc\") \n",
    "\n",
    "    fid = \"/tmp/\"+file_prefix+\".\"+str(i)+\".nc\"\n",
    "    nc_fid = netCDF4.Dataset(fid)\n",
    "    if i==start_year:\n",
    "      time = nc_fid.variables['time'][:].data\n",
    "      subset_time = [dt.datetime(1800,1,1) + dt.timedelta(hours=t) for t in time]\n",
    "      vartmp = nc_fid.variables[varname][:]  # shape is time, lat, lon as shown above\n",
    "      latsubset, lonsubset, varsubset=extractCB(vartmp.data,narr_lats,narr_lons,latrange,lonrange)\n",
    "      print(i,varname,'data imported','\\n')\n",
    "    else:\n",
    "      time = nc_fid.variables['time'][:].data\n",
    "      dt_tmp = [dt.datetime(1800,1,1) + dt.timedelta(hours=t) for t in time]\n",
    "      subset_time = np.append(subset_time,dt_tmp)\n",
    "      vartmp = nc_fid.variables[varname][:]  # shape is time, lat, lon as shown above\n",
    "      _, _, varsubsettmp=extractCB(vartmp.data,narr_lats,narr_lons,latrange,lonrange)\n",
    "      varsubset=np.vstack((varsubset,varsubsettmp))\n",
    "      print(i,varname,'data imported','\\n')\n",
    "  return varsubset, subset_time, latsubset, lonsubset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998 air data imported \n",
      "\n",
      "1999 air data imported \n",
      "\n",
      "2000 air data imported \n",
      "\n",
      "2001 air data imported \n",
      "\n",
      "2002 air data imported \n",
      "\n",
      "2003 air data imported \n",
      "\n",
      "2004 air data imported \n",
      "\n",
      "2005 air data imported \n",
      "\n",
      "2006 air data imported \n",
      "\n",
      "2007 air data imported \n",
      "\n",
      "2008 air data imported \n",
      "\n",
      "2009 air data imported \n",
      "\n",
      "2010 air data imported \n",
      "\n",
      "2011 air data imported \n",
      "\n",
      "2012 air data imported \n",
      "\n",
      "2013 air data imported \n",
      "\n",
      "2014 air data imported \n",
      "\n",
      "2015 air data imported \n",
      "\n",
      "2016 air data imported \n",
      "\n",
      "2017 air data imported \n",
      "\n",
      "2018 air data imported \n",
      "\n",
      "2019 air data imported \n",
      "\n",
      "2020 air data imported \n",
      "\n"
     ]
    }
   ],
   "source": [
    "filesprefix = 'air.2m'\n",
    "varnames = 'air'\n",
    "airsubset, time_narr_import, lat_subset, long_subset = narr_subset_variable(filesprefix,\n",
    "                                                                           varnames,\n",
    "                                                                           start_yr,\n",
    "                                                                           end_yr,\n",
    "                                                                           narrlats,\n",
    "                                                                           narrlons,\n",
    "                                                                           lat_range,\n",
    "                                                                           long_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998 apcp data imported \n",
      "\n",
      "1999 apcp data imported \n",
      "\n",
      "2000 apcp data imported \n",
      "\n",
      "2001 apcp data imported \n",
      "\n",
      "2002 apcp data imported \n",
      "\n",
      "2003 apcp data imported \n",
      "\n",
      "2004 apcp data imported \n",
      "\n",
      "2005 apcp data imported \n",
      "\n",
      "2006 apcp data imported \n",
      "\n",
      "2007 apcp data imported \n",
      "\n",
      "2008 apcp data imported \n",
      "\n",
      "2009 apcp data imported \n",
      "\n",
      "2010 apcp data imported \n",
      "\n",
      "2011 apcp data imported \n",
      "\n",
      "2012 apcp data imported \n",
      "\n",
      "2013 apcp data imported \n",
      "\n",
      "2014 apcp data imported \n",
      "\n",
      "2015 apcp data imported \n",
      "\n",
      "2016 apcp data imported \n",
      "\n",
      "2017 apcp data imported \n",
      "\n",
      "2018 apcp data imported \n",
      "\n",
      "2019 apcp data imported \n",
      "\n",
      "2020 apcp data imported \n",
      "\n",
      "1998 uwnd data imported \n",
      "\n",
      "1999 uwnd data imported \n",
      "\n",
      "2000 uwnd data imported \n",
      "\n",
      "2001 uwnd data imported \n",
      "\n",
      "2002 uwnd data imported \n",
      "\n",
      "2003 uwnd data imported \n",
      "\n",
      "2004 uwnd data imported \n",
      "\n",
      "2005 uwnd data imported \n",
      "\n",
      "2006 uwnd data imported \n",
      "\n",
      "2007 uwnd data imported \n",
      "\n",
      "2008 uwnd data imported \n",
      "\n",
      "2009 uwnd data imported \n",
      "\n",
      "2010 uwnd data imported \n",
      "\n",
      "2011 uwnd data imported \n",
      "\n",
      "2012 uwnd data imported \n",
      "\n",
      "2013 uwnd data imported \n",
      "\n",
      "2014 uwnd data imported \n",
      "\n",
      "2015 uwnd data imported \n",
      "\n",
      "2016 uwnd data imported \n",
      "\n",
      "2017 uwnd data imported \n",
      "\n",
      "2018 uwnd data imported \n",
      "\n",
      "2019 uwnd data imported \n",
      "\n",
      "2020 uwnd data imported \n",
      "\n",
      "1998 vwnd data imported \n",
      "\n",
      "1999 vwnd data imported \n",
      "\n",
      "2000 vwnd data imported \n",
      "\n",
      "2001 vwnd data imported \n",
      "\n",
      "2002 vwnd data imported \n",
      "\n",
      "2003 vwnd data imported \n",
      "\n",
      "2004 vwnd data imported \n",
      "\n",
      "2005 vwnd data imported \n",
      "\n",
      "2006 vwnd data imported \n",
      "\n",
      "2007 vwnd data imported \n",
      "\n",
      "2008 vwnd data imported \n",
      "\n",
      "2009 vwnd data imported \n",
      "\n",
      "2010 vwnd data imported \n",
      "\n",
      "2011 vwnd data imported \n",
      "\n",
      "2012 vwnd data imported \n",
      "\n",
      "2013 vwnd data imported \n",
      "\n",
      "2014 vwnd data imported \n",
      "\n",
      "2015 vwnd data imported \n",
      "\n",
      "2016 vwnd data imported \n",
      "\n",
      "2017 vwnd data imported \n",
      "\n",
      "2018 vwnd data imported \n",
      "\n",
      "2019 vwnd data imported \n",
      "\n",
      "2020 vwnd data imported \n",
      "\n",
      "1998 rhum data imported \n",
      "\n",
      "1999 rhum data imported \n",
      "\n",
      "2000 rhum data imported \n",
      "\n",
      "2001 rhum data imported \n",
      "\n",
      "2002 rhum data imported \n",
      "\n",
      "2003 rhum data imported \n",
      "\n",
      "2004 rhum data imported \n",
      "\n",
      "2005 rhum data imported \n",
      "\n",
      "2006 rhum data imported \n",
      "\n",
      "2007 rhum data imported \n",
      "\n",
      "2008 rhum data imported \n",
      "\n",
      "2009 rhum data imported \n",
      "\n",
      "2010 rhum data imported \n",
      "\n",
      "2011 rhum data imported \n",
      "\n",
      "2012 rhum data imported \n",
      "\n",
      "2013 rhum data imported \n",
      "\n",
      "2014 rhum data imported \n",
      "\n",
      "2015 rhum data imported \n",
      "\n",
      "2016 rhum data imported \n",
      "\n",
      "2017 rhum data imported \n",
      "\n",
      "2018 rhum data imported \n",
      "\n",
      "2019 rhum data imported \n",
      "\n",
      "2020 rhum data imported \n",
      "\n",
      "1998 lcdc data imported \n",
      "\n",
      "1999 lcdc data imported \n",
      "\n",
      "2000 lcdc data imported \n",
      "\n",
      "2001 lcdc data imported \n",
      "\n",
      "2002 lcdc data imported \n",
      "\n",
      "2003 lcdc data imported \n",
      "\n",
      "2004 lcdc data imported \n",
      "\n",
      "2005 lcdc data imported \n",
      "\n",
      "2006 lcdc data imported \n",
      "\n",
      "2007 lcdc data imported \n",
      "\n",
      "2008 lcdc data imported \n",
      "\n",
      "2009 lcdc data imported \n",
      "\n",
      "2010 lcdc data imported \n",
      "\n",
      "2011 lcdc data imported \n",
      "\n",
      "2012 lcdc data imported \n",
      "\n",
      "2013 lcdc data imported \n",
      "\n",
      "2014 lcdc data imported \n",
      "\n",
      "2015 lcdc data imported \n",
      "\n",
      "2016 lcdc data imported \n",
      "\n",
      "2017 lcdc data imported \n",
      "\n",
      "2018 lcdc data imported \n",
      "\n",
      "2019 lcdc data imported \n",
      "\n",
      "2020 lcdc data imported \n",
      "\n",
      "1998 ssrun data imported \n",
      "\n",
      "1999 ssrun data imported \n",
      "\n",
      "2000 ssrun data imported \n",
      "\n",
      "2001 ssrun data imported \n",
      "\n",
      "2002 ssrun data imported \n",
      "\n",
      "2003 ssrun data imported \n",
      "\n",
      "2004 ssrun data imported \n",
      "\n",
      "2005 ssrun data imported \n",
      "\n",
      "2006 ssrun data imported \n",
      "\n",
      "2007 ssrun data imported \n",
      "\n",
      "2008 ssrun data imported \n",
      "\n",
      "2009 ssrun data imported \n",
      "\n",
      "2010 ssrun data imported \n",
      "\n",
      "2011 ssrun data imported \n",
      "\n",
      "2012 ssrun data imported \n",
      "\n",
      "2013 ssrun data imported \n",
      "\n",
      "2014 ssrun data imported \n",
      "\n",
      "2015 ssrun data imported \n",
      "\n",
      "2016 ssrun data imported \n",
      "\n",
      "2017 ssrun data imported \n",
      "\n",
      "2018 ssrun data imported \n",
      "\n",
      "2019 ssrun data imported \n",
      "\n",
      "2020 ssrun data imported \n",
      "\n",
      "1998 air data imported \n",
      "\n",
      "1999 air data imported \n",
      "\n",
      "2000 air data imported \n",
      "\n",
      "2001 air data imported \n",
      "\n",
      "2002 air data imported \n",
      "\n",
      "2003 air data imported \n",
      "\n",
      "2004 air data imported \n",
      "\n",
      "2005 air data imported \n",
      "\n",
      "2006 air data imported \n",
      "\n",
      "2007 air data imported \n",
      "\n",
      "2008 air data imported \n",
      "\n",
      "2009 air data imported \n",
      "\n",
      "2010 air data imported \n",
      "\n",
      "2011 air data imported \n",
      "\n",
      "2012 air data imported \n",
      "\n",
      "2013 air data imported \n",
      "\n",
      "2014 air data imported \n",
      "\n",
      "2015 air data imported \n",
      "\n",
      "2016 air data imported \n",
      "\n",
      "2017 air data imported \n",
      "\n",
      "2018 air data imported \n",
      "\n",
      "2019 air data imported \n",
      "\n",
      "2020 air data imported \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "var_data = defaultdict(list)\n",
    "\n",
    "filesprefix = ['apcp','uwnd.10m','vwnd.10m','rhum.2m','lcdc','ssrun','air.sfc',]\n",
    "varnames = ['apcp','uwnd','vwnd','rhum','lcdc','ssrun','air']\n",
    "# filesprefix = ['rhum.2m','lcdc','ssrun','air.sfc','apcp']\n",
    "# varnames = ['rhum','lcdc','ssrun','air','apcp']\n",
    "\n",
    "\n",
    "\n",
    "for fileprefix, varname in zip(filesprefix,varnames):\n",
    "    cvarsubset, _, _, _ = narr_subset_variable(fileprefix,\n",
    "                                              varname,\n",
    "                                              start_yr,\n",
    "                                              end_yr,\n",
    "                                              narrlats,\n",
    "                                              narrlons,\n",
    "                                              lat_range,\n",
    "                                              long_range)\n",
    "    \n",
    "    var_data[varname]=cvarsubset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the time indices in the NARR timeseries corresponding to CMC and CBP measurements\n",
    "\n",
    "# make a dataframe and make the narr timestamps the index\n",
    "narrtdf=pd.DataFrame({'Datetime':pd.DatetimeIndex(time_narr_import)})\n",
    "narrtdf=narrtdf.set_index('Datetime')\n",
    "\n",
    "# make a new empty array for the time indices\n",
    "narr_tind=np.array([],dtype=int) \n",
    "\n",
    "for i in range(len(daterange)):\n",
    "  ttmp=daterange[i]\n",
    "  #if CMC/CBP data are newer than the last timestamp for NARR data\n",
    "  if (pd.to_datetime(ttmp)>narrtdf.index[-1]): \n",
    "    tmpind=-1\n",
    "  else:\n",
    "    tmpind=narrtdf.index.get_loc(ttmp,method='bfill')\n",
    "  narr_tind=np.append(narr_tind,tmpind)\n",
    "  \n",
    "# save narr_tind as integer \n",
    "narr_tind=narr_tind.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if CMC/CBP data are newer than April 2020, when the NARR data stops, \n",
    "# keep track of those indices so you can NaN the data later \n",
    "naninds=np.where(narr_tind==-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# first, combine the CMC and CBP coordinates and zip location data\n",
    "\n",
    "#CMC and CBP coordinates \n",
    "allcoord = list(zip(loc_df.Latitude,loc_df.Longitude))\n",
    "\n",
    "#NARR coordinates \n",
    "narrcoord = list(zip(np.ravel(lat_subset), np.ravel(long_subset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then, find the closest NARR grid cell to the CMC and CBP coordinates \n",
    "\n",
    "# make a kdtree for the narr coordinates, then query it for the CMC/CBP coordinates\n",
    "tree = KDTree(narrcoord)\n",
    "\n",
    "# query and obtain corresponding climate data\n",
    "narrxyid=tree.query(allcoord,k=1)\n",
    "\n",
    "#get the matrix indices for the re-rolled matrix to correspond to the airtemp data\n",
    "narrxy_ind1=(np.floor(narrxyid[1]/lat_subset.shape[1])).astype(int)\n",
    "narrxy_ind2=(narrxyid[1]-narrxy_ind1*lat_subset.shape[1]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 21)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat_subset.shape#narrxyid[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38.6336, -75.6177)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allcoord[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38.5583, -75.5696) (38.42746, -75.55963)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(38.42746, -75.55963)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that the coordinates are close to each other \n",
    "h=9\n",
    "print(allcoord[h],narrcoord[narrxyid[1][h]])\n",
    "lat_subset[narrxy_ind1[h],narrxy_ind2[h]],long_subset[narrxy_ind1[h],narrxy_ind2[h]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryan\\Anaconda3\\envs\\hacktb\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (3,7,8,9,10,11,14,15,16,17,18,19,22) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "all_data=pd.read_csv(os.path.join(PROJ_ROOT, \n",
    "                         'data',\n",
    "                        'processed',\n",
    "                         'lc_pol_merged_data.csv'), parse_dates=['new_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract air temp and convert kelvin to celsius\n",
    "# nan the data that's too recent\n",
    "narr_data_airtemp=airsubset[narr_tind,narrxy_ind1,narrxy_ind2]-273.15\n",
    "narr_data_airtemp[naninds]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['apcp', 'uwnd', 'vwnd', 'rhum', 'lcdc', 'ssrun', 'air'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_data_subset = defaultdict(lambda: 'Not Present')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for varname, varsubset in var_data.items():\n",
    "    tmp = varsubset[narr_tind,narrxy_ind1,narrxy_ind2]\n",
    "    tmp[naninds]=np.nan\n",
    "    var_data_subset[varname]=tmp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-22 15:00:00 2019-03-23 15:00:00 2019-03-24 15:00:00\n"
     ]
    }
   ],
   "source": [
    "# over the 24 and 48 hours before the sampling event\n",
    "hr24=narr_tind-8\n",
    "hr48=narr_tind-16\n",
    "print(time_narr_import[hr48[0]],time_narr_import[hr24[0]],time_narr_import[narr_tind[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add up the cumulative precipitation 24 hours before the sampling event \n",
    "tmp=var_data['apcp'][hr24,narrxy_ind1,narrxy_ind2]\n",
    "\n",
    "for i in range(1,8):\n",
    "  #print(time_narr_import[hr24[0]+i])\n",
    "  tmp=np.vstack((tmp,var_data['apcp'][(hr24+i),narrxy_ind1,narrxy_ind2]))\n",
    "\n",
    "narr_precip24=np.sum(tmp,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add up the cumulative precipitation 48 hours before the sampling event \n",
    "tmp=var_data['apcp'][hr48,narrxy_ind1,narrxy_ind2]\n",
    "\n",
    "for i in range(1,16):\n",
    "  #print(time_narr_import[hr48[0]+i])\n",
    "  tmp=np.vstack((tmp,var_data['apcp'][(hr24+i),narrxy_ind1,narrxy_ind2]))\n",
    "\n",
    "narr_precip48=np.sum(tmp,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nan the naninds for the precip24, precip48 variables\n",
    "narr_precip24[naninds]=np.nan\n",
    "narr_precip48[naninds]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# var_data_subset['air'] = var_data_subset['air'] - 273\n",
    "# var_data_subset['air'] = var_data_subset['air'] - .15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "narr_windspeed = np.sqrt(var_data_subset['uwnd']**2 +var_data_subset['vwnd']**2)\n",
    "narr_dir= 270-(np.arctan(-var_data_subset['vwnd'],var_data_subset['uwnd'])*57.29578)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "narr_data = pd.concat([pd.DataFrame(data=narr_data_airtemp,columns=['airtemp_narr']),\n",
    "                          pd.DataFrame(data=var_data_subset['apcp'],columns=['precip3_narr']),\n",
    "                          pd.DataFrame(data=var_data_subset['rhum'],columns=['humidity_narr']),\n",
    "                          pd.DataFrame(data=var_data_subset['lcdc'],columns=['cl_cover_narr']),\n",
    "                          pd.DataFrame(data=var_data_subset['ssrun'],columns=['sfc_runoff']),\n",
    "                          pd.DataFrame(data=var_data_subset['air'],columns=['sfc_air_narr']),\n",
    "                          pd.DataFrame(data=var_data_subset['uwnd'],columns=['u_wind_narr']),\n",
    "                          pd.DataFrame(data=var_data_subset['vwnd'],columns=['v_wind_narr']),\n",
    "                          pd.DataFrame(data=narr_windspeed,columns=['windspeed_narr']),\n",
    "                          pd.DataFrame(data=narr_dir,columns=['wdirection_narr']),\n",
    "                          pd.DataFrame(data=narr_precip24,columns=['precip24_narr']),\n",
    "                          pd.DataFrame(data=narr_precip48,columns=['precip48_narr'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airtemp_narr</th>\n",
       "      <th>precip3_narr</th>\n",
       "      <th>humidity_narr</th>\n",
       "      <th>cl_cover_narr</th>\n",
       "      <th>sfc_runoff</th>\n",
       "      <th>sfc_air_narr</th>\n",
       "      <th>u_wind_narr</th>\n",
       "      <th>v_wind_narr</th>\n",
       "      <th>windspeed_narr</th>\n",
       "      <th>wdirection_narr</th>\n",
       "      <th>precip24_narr</th>\n",
       "      <th>precip48_narr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.475159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.314972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.100952</td>\n",
       "      <td>-0.871403</td>\n",
       "      <td>1.188705</td>\n",
       "      <td>2.768492</td>\n",
       "      <td>319.927734</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.475159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.314972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.100952</td>\n",
       "      <td>-0.732618</td>\n",
       "      <td>0.899643</td>\n",
       "      <td>4.375051</td>\n",
       "      <td>311.975891</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.475159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.314972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.100952</td>\n",
       "      <td>-0.871403</td>\n",
       "      <td>1.188705</td>\n",
       "      <td>2.768492</td>\n",
       "      <td>319.927734</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.404327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.768684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>291.421509</td>\n",
       "      <td>-1.326357</td>\n",
       "      <td>4.009186</td>\n",
       "      <td>4.656967</td>\n",
       "      <td>345.994659</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.008444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.404327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.768684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>291.421509</td>\n",
       "      <td>-1.326357</td>\n",
       "      <td>4.009186</td>\n",
       "      <td>4.656967</td>\n",
       "      <td>345.994659</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.008444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103290</th>\n",
       "      <td>5.855164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.959641</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278.570374</td>\n",
       "      <td>1.316453</td>\n",
       "      <td>-3.846542</td>\n",
       "      <td>3.906379</td>\n",
       "      <td>194.572815</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103291</th>\n",
       "      <td>2.192596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.256569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>273.911987</td>\n",
       "      <td>1.268207</td>\n",
       "      <td>-3.203323</td>\n",
       "      <td>3.425949</td>\n",
       "      <td>197.337097</td>\n",
       "      <td>1.056926</td>\n",
       "      <td>7.525676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103292</th>\n",
       "      <td>-1.641449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.074768</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.830383</td>\n",
       "      <td>0.959544</td>\n",
       "      <td>-1.426971</td>\n",
       "      <td>1.968258</td>\n",
       "      <td>215.022186</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103293</th>\n",
       "      <td>4.546539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.312500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>276.410034</td>\n",
       "      <td>-1.004335</td>\n",
       "      <td>1.572357</td>\n",
       "      <td>3.312654</td>\n",
       "      <td>327.544128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103294</th>\n",
       "      <td>5.864105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.064972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.596069</td>\n",
       "      <td>0.858258</td>\n",
       "      <td>-1.157471</td>\n",
       "      <td>2.045784</td>\n",
       "      <td>220.825470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103295 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        airtemp_narr  precip3_narr  humidity_narr  cl_cover_narr  sfc_runoff  \\\n",
       "0          10.475159           0.0      50.314972            0.0         0.0   \n",
       "1          10.475159           0.0      50.314972            0.0         0.0   \n",
       "2          10.475159           0.0      50.314972            0.0         0.0   \n",
       "3          13.404327           0.0      43.768684            0.0         0.0   \n",
       "4          13.404327           0.0      43.768684            0.0         0.0   \n",
       "...              ...           ...            ...            ...         ...   \n",
       "103290      5.855164           0.0      87.959641           57.0         0.0   \n",
       "103291      2.192596           0.0      91.256569            0.0         0.0   \n",
       "103292     -1.641449           0.0      96.074768            2.0         0.0   \n",
       "103293      4.546539           0.0      93.312500            0.0         0.0   \n",
       "103294      5.864105           0.0      94.064972            0.0         0.0   \n",
       "\n",
       "        sfc_air_narr  u_wind_narr  v_wind_narr  windspeed_narr  \\\n",
       "0         289.100952    -0.871403     1.188705        2.768492   \n",
       "1         289.100952    -0.732618     0.899643        4.375051   \n",
       "2         289.100952    -0.871403     1.188705        2.768492   \n",
       "3         291.421509    -1.326357     4.009186        4.656967   \n",
       "4         291.421509    -1.326357     4.009186        4.656967   \n",
       "...              ...          ...          ...             ...   \n",
       "103290    278.570374     1.316453    -3.846542        3.906379   \n",
       "103291    273.911987     1.268207    -3.203323        3.425949   \n",
       "103292    270.830383     0.959544    -1.426971        1.968258   \n",
       "103293    276.410034    -1.004335     1.572357        3.312654   \n",
       "103294    277.596069     0.858258    -1.157471        2.045784   \n",
       "\n",
       "        wdirection_narr  precip24_narr  precip48_narr  \n",
       "0            319.927734       0.000631       0.000631  \n",
       "1            311.975891       0.000631       0.000631  \n",
       "2            319.927734       0.000631       0.000631  \n",
       "3            345.994659       0.000631       0.008444  \n",
       "4            345.994659       0.000631       0.008444  \n",
       "...                 ...            ...            ...  \n",
       "103290       194.572815       0.046875       0.046875  \n",
       "103291       197.337097       1.056926       7.525676  \n",
       "103292       215.022186       0.039062       3.500000  \n",
       "103293       327.544128       0.000000       0.000000  \n",
       "103294       220.825470       0.000000       0.046875  \n",
       "\n",
       "[103295 rows x 12 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "narr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103295, 12)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "narr_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103295, 58)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.concat([all_data, narr_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_date</th>\n",
       "      <th>CloudCover</th>\n",
       "      <th>GaugeHeight</th>\n",
       "      <th>GroupCode</th>\n",
       "      <th>HUC12</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Method</th>\n",
       "      <th>Other Conditions</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>...</th>\n",
       "      <th>humidity_narr</th>\n",
       "      <th>cl_cover_narr</th>\n",
       "      <th>sfc_runoff</th>\n",
       "      <th>sfc_air_narr</th>\n",
       "      <th>u_wind_narr</th>\n",
       "      <th>v_wind_narr</th>\n",
       "      <th>windspeed_narr</th>\n",
       "      <th>wdirection_narr</th>\n",
       "      <th>precip24_narr</th>\n",
       "      <th>precip48_narr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-03-24 12:28:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NWA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.6336</td>\n",
       "      <td>-75.6177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>50.314972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.100952</td>\n",
       "      <td>-0.871403</td>\n",
       "      <td>1.188705</td>\n",
       "      <td>2.768492</td>\n",
       "      <td>319.927734</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-03-24 12:46:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NWA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.6422</td>\n",
       "      <td>-75.6068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>50.314972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.100952</td>\n",
       "      <td>-0.732618</td>\n",
       "      <td>0.899643</td>\n",
       "      <td>4.375051</td>\n",
       "      <td>311.975891</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-03-24 13:05:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NWA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.6013</td>\n",
       "      <td>-75.6563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>50.314972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.100952</td>\n",
       "      <td>-0.871403</td>\n",
       "      <td>1.188705</td>\n",
       "      <td>2.768492</td>\n",
       "      <td>319.927734</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-03-24 15:20:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NWA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.5645</td>\n",
       "      <td>-75.6723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>43.768684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>291.421509</td>\n",
       "      <td>-1.326357</td>\n",
       "      <td>4.009186</td>\n",
       "      <td>4.656967</td>\n",
       "      <td>345.994659</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.008444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-03-24 15:34:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NWA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.5583</td>\n",
       "      <td>-75.5696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>43.768684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>291.421509</td>\n",
       "      <td>-1.326357</td>\n",
       "      <td>4.009186</td>\n",
       "      <td>4.656967</td>\n",
       "      <td>345.994659</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.008444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             new_date CloudCover  GaugeHeight GroupCode  HUC12  Latitude  \\\n",
       "0 2019-03-24 12:28:00        NaN          NaN       NWA    NaN   38.6336   \n",
       "1 2019-03-24 12:46:00        NaN          NaN       NWA    NaN   38.6422   \n",
       "2 2019-03-24 13:05:00        NaN          NaN       NWA    NaN   38.6013   \n",
       "3 2019-03-24 15:20:00        NaN          NaN       NWA    NaN   38.5645   \n",
       "4 2019-03-24 15:34:00        NaN          NaN       NWA    NaN   38.5583   \n",
       "\n",
       "   Longitude Method Other Conditions Rainfall  ... humidity_narr  \\\n",
       "0   -75.6177    NaN              NaN      NaN  ...     50.314972   \n",
       "1   -75.6068    NaN              NaN      NaN  ...     50.314972   \n",
       "2   -75.6563    NaN              NaN      NaN  ...     50.314972   \n",
       "3   -75.6723    NaN              NaN      NaN  ...     43.768684   \n",
       "4   -75.5696    NaN              NaN      NaN  ...     43.768684   \n",
       "\n",
       "  cl_cover_narr  sfc_runoff  sfc_air_narr u_wind_narr v_wind_narr  \\\n",
       "0           0.0         0.0    289.100952   -0.871403    1.188705   \n",
       "1           0.0         0.0    289.100952   -0.732618    0.899643   \n",
       "2           0.0         0.0    289.100952   -0.871403    1.188705   \n",
       "3           0.0         0.0    291.421509   -1.326357    4.009186   \n",
       "4           0.0         0.0    291.421509   -1.326357    4.009186   \n",
       "\n",
       "  windspeed_narr wdirection_narr precip24_narr precip48_narr  \n",
       "0       2.768492      319.927734      0.000631      0.000631  \n",
       "1       4.375051      311.975891      0.000631      0.000631  \n",
       "2       2.768492      319.927734      0.000631      0.000631  \n",
       "3       4.656967      345.994659      0.000631      0.008444  \n",
       "4       4.656967      345.994659      0.000631      0.008444  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['new_date', 'CloudCover', 'GaugeHeight', 'GroupCode', 'HUC12',\n",
       "       'Latitude', 'Longitude', 'Method', 'Other Conditions', 'Rainfall',\n",
       "       'Rainfall Within 24 Hours', 'Rainfall Within 48 Hours', 'SampleDepth',\n",
       "       'SampleId', 'Station', 'StationCode', 'StationName',\n",
       "       'Weather Conditions Day Before Yesterday', 'Weather Conditions Today',\n",
       "       'Weather Conditions Yesterday', 'WindDirection', 'WindSpeed', 'state',\n",
       "       'HUC12_', 'HUCNAME_', 'FIPS_', 'COUNTY_', 'STATE_', 'areaacres',\n",
       "       'states', 'huc12', 'za_mean', 'lc_0', 'lc_11', 'lc_21', 'lc_22',\n",
       "       'lc_23', 'lc_24', 'lc_31', 'lc_41', 'lc_42', 'lc_43', 'lc_52', 'lc_71',\n",
       "       'lc_81', 'lc_82', 'lc_90', 'lc_95', 'month', 'year', 'week',\n",
       "       'dayofweek', 'hour', 'min', 'quarter', 'DO', 'TN', 'TP', 'airtemp_narr',\n",
       "       'precip3_narr', 'humidity_narr', 'cl_cover_narr', 'sfc_runoff',\n",
       "       'sfc_air_narr', 'u_wind_narr', 'v_wind_narr', 'windspeed_narr',\n",
       "       'wdirection_narr', 'precip24_narr', 'precip48_narr'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_date</th>\n",
       "      <th>airtemp_narr</th>\n",
       "      <th>sfc_air_narr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2019-06-02 15:08:00</td>\n",
       "      <td>29.172485</td>\n",
       "      <td>306.845459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2019-06-02 15:50:00</td>\n",
       "      <td>29.172485</td>\n",
       "      <td>306.845459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2019-06-02 18:07:00</td>\n",
       "      <td>28.540924</td>\n",
       "      <td>302.314941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2019-06-02 18:32:00</td>\n",
       "      <td>28.540924</td>\n",
       "      <td>302.314941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2019-06-02 18:50:00</td>\n",
       "      <td>28.540924</td>\n",
       "      <td>302.314941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103252</th>\n",
       "      <td>2016-06-14 09:05:00</td>\n",
       "      <td>21.633698</td>\n",
       "      <td>296.743835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103263</th>\n",
       "      <td>2018-06-13 08:45:00</td>\n",
       "      <td>20.713531</td>\n",
       "      <td>293.471924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103265</th>\n",
       "      <td>2018-06-05 08:00:00</td>\n",
       "      <td>18.267242</td>\n",
       "      <td>290.462036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103273</th>\n",
       "      <td>2016-06-09 08:15:00</td>\n",
       "      <td>13.088043</td>\n",
       "      <td>284.611084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103276</th>\n",
       "      <td>2017-06-13 09:00:00</td>\n",
       "      <td>20.394928</td>\n",
       "      <td>292.869141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10162 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  new_date  airtemp_narr  sfc_air_narr\n",
       "128    2019-06-02 15:08:00     29.172485    306.845459\n",
       "129    2019-06-02 15:50:00     29.172485    306.845459\n",
       "130    2019-06-02 18:07:00     28.540924    302.314941\n",
       "131    2019-06-02 18:32:00     28.540924    302.314941\n",
       "132    2019-06-02 18:50:00     28.540924    302.314941\n",
       "...                    ...           ...           ...\n",
       "103252 2016-06-14 09:05:00     21.633698    296.743835\n",
       "103263 2018-06-13 08:45:00     20.713531    293.471924\n",
       "103265 2018-06-05 08:00:00     18.267242    290.462036\n",
       "103273 2016-06-09 08:15:00     13.088043    284.611084\n",
       "103276 2017-06-13 09:00:00     20.394928    292.869141\n",
       "\n",
       "[10162 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df[total_df.new_date.map(lambda x: x.month)==6][['new_date','airtemp_narr','sfc_air_narr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.to_csv(os.path.join(PROJ_ROOT, \n",
    "                         'data',\n",
    "                        'processed',\n",
    "                'narr_data.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hacktb",
   "language": "python",
   "name": "hacktb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
